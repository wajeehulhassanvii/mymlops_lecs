{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- connect to metadata store\n",
    "- log metadata\n",
    "- list metadata\n",
    "- kubeflow artifact dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then we import metadata as \"import kubeflow.metadata as metadata\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when we create kubeflow, we also get assigned a new kubeflow metadata-artefact-store, which we can access with a URL, to be used in metadata code for loggin metadat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- then we create workspace, we can call workspace a high level bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we can take run as a logical grouping of multiple execution, where each execution can involve diff experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## first push custom image which will install custom libraries for the application"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "5/demos/demo/m4-kubeflow-train/demo02-custom-image/steps.md \n",
    "### Build and Push Image\n",
    "\n",
    "```bash\n",
    "PROJECT_ID=$(gcloud config get-value core/project)\n",
    "IMAGE_NAME=tensorflow-2.1.0-jupyter\n",
    "IMAGE_NAME=gcr.io/$PROJECT_ID/$IMAGE_NAME\n",
    "IMAGE_TAG=latest\n",
    "\n",
    "# build image\n",
    "docker build -t $IMAGE_NAME:$IMAGE_TAG .\n",
    "# run locally to test\n",
    "docker run -it --rm -p 8888:8888 -p 6006:6006 -v $(pwd):/home/jovyan $IMAGE_NAME:$IMAGE_TAG\n",
    "# authorize docker\n",
    "gcloud auth configure-docker --quiet\n",
    "# push image\n",
    "docker push $IMAGE_NAME:$IMAGE_TAG\n",
    "```\n",
    "\n",
    "### create Notebook\n",
    "\n",
    "- Open Kubeflow central dashboard.\n",
    "- Go to notebook servers\n",
    "- Select namespace from the top drop-down\n",
    "- Create notebook using create button\n",
    "- Set the notebook name\n",
    "- Use the custom image \n",
    "- set CPU, RAM, Workspace Volume, data volume\n",
    "- Select config and select **\"ADD GCP credentials\"**\n",
    "- Click on **\"Launch\"**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note: we stored a variable IMAGE_NAME with the image name, which can be used in creating a notebook server<br>\n",
    "we can get image name as \"echo $IMAGE_NAME\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To debug notebook server\n",
    "1. go to kubernetes engine \n",
    "2. then go to clusters\n",
    "3. then go open the cluster, and copy the command\n",
    "4. paste the command in terminal\n",
    "- do **kubectl get notebook (name of notebook server) -n (kubeflow namespace we efined while createing notebook server)**\n",
    "5. we can also describe the notebook by modifying the above command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING in notebook environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train like a normal tensorfllow problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### to run tensorboard \n",
    "- in notebook server open terminal\n",
    "- **tensorboard --logdir=/home/jovyan/logs --bind_all** will run tensorboard on port 6006<br>\n",
    "- kubectl port-forward -n (namespace) (notebook_name)-0 6006:6006 will make the notebook pod accessible\n",
    "- **then we can access tensorboard from localhost:6006**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## saving model\n",
    "- we can save as .h5 file which is Keras specific\n",
    "- otherwise we can save the file using tf.keras.models.load_model(filename) which is very generic and can be used in browser, server,edge devices. produces generic graph and weights\n",
    "- ---------!saved_model_cli show --dir export/ --tag_set serve --signature_def serving_default---------- command will let us check model signature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save model in external storage\n",
    "- we first connect to storage \n",
    "- then we create the bucket with project_id, and bucket id, but first we delete the existing bucket\n",
    "- define bucket variable == \"gs://{0}-fashion-mnist/export/001\".format(project_id[0])\n",
    "- then we upload the model file with Storage.upload('export', bucket)\n",
    "- remember google credentials have already been injeccted into the notebook server"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "we can check credentials as $GOOGLE_APPLICATION_CREDENTIALS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check storage and bucket in GCP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- go to storage -> browser and check the exported model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## METADATA of models in METADATA STORE, and watch METADATA INFO on kubeflow artefact dashboard\n",
    "- soon everything become clutered if we are working in a  team. To keep track, we will leverage kubeflow metadata\n",
    "- metadata is exposed on METADATA HOST on port 8080\n",
    "- default METADATA host is 'metadata-grpc-service.kubeflow'\n",
    "- take workspace as a high level bucket\n",
    "    - we can give name, description and any label to the workspace\n",
    "- then we can create run, we can take run as a logical grouping of multiple executions\n",
    "    - each execution can involve different experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model metadata \n",
    "- for each execution, we can store different informations lie name, description, owner, uri, model_type, training_framework, hyperparametes, version, labels, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset metadata\n",
    "- we can also log metadata as data set using metadata.Dataset function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### metadata metrics\n",
    "- we can also log model metrics like loss, accuracy, etc "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## query metadata\n",
    "- we can query the metadata and their artefacts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KUBEFLOW artefacts\n",
    "- we can also build dashboard for teaam or project.\n",
    "- artefact store will show all the metadaata we created"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
