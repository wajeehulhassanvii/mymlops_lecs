{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- serve model with kfserving\n",
    "    - serve model as an API\n",
    "    - invoke model API for prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we set up kind as **InferenceService** for serving\n",
    "- we create resouce in **kubeflow** namespace\n",
    "- in spec we mention tf model\n",
    "- we configure storage where we store model\n",
    "    - GS location\n",
    "- we also define the service account to kf-user so the host can use google storage\n",
    "- **kf-user** is created alongwith deployment process only\n",
    "- minReplica=1 means keep one replica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we also need to enable **inferenceservice** on kubeflow namespace, we can do that by running the below command:\n",
    "**kubectl label namespace kubeflow serving.kubeflow.org/inferenceservice=enabled**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input to kfserving, after applying InferenceService to kubernetes cluster\n",
    "- KFServing expects input to be in a specific JSON format\n",
    "- with python script we can normalize the dataset, then reshape to 28 by 28, take 5 example and save in JSON format, as below, which requires tensorflow to be installed locally"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# load data\n",
    "ds_train = tfds.load(name=\"fashion_mnist:1.0.0\", split=\"train\")\n",
    "\n",
    "# create samples\n",
    "NUM_EXAMPLE=5\n",
    "samples=[]\n",
    "for row in ds_train.take(NUM_EXAMPLE):\n",
    "    image, label = row[\"image\"], row[\"label\"]\n",
    "    \n",
    "    # preprocessing\n",
    "    image = image.numpy() / 255.0\n",
    "    image = image.reshape(28, 28, 1)\n",
    "    samples.append(image.tolist())\n",
    "    \n",
    "# prepare test data\n",
    "data = json.dumps({\"instances\": samples})\n",
    "data_read = json.loads(data)\n",
    "with open('fashion_mnist_input.json','w') as out:\n",
    "    json.dump(data_read, out)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "steps::::\n",
    "\n",
    "\n",
    "### KFserving : Basic\n",
    "\n",
    "#### Setup KFServing \n",
    "Enable inferenceservice on `kubeflow` namespace\n",
    "\n",
    "```bash\n",
    "kubectl label namespace kubeflow serving.kubeflow.org/inferenceservice=enabled\n",
    "```\n",
    "\n",
    "#### Create KFserving inferenceservice\n",
    "\n",
    "Change the model storage URI in the `fashion-mnist-serving-default.yaml`. eg. `gs://<GCS_BUCKET_NAME>/export`\n",
    "Apply the YAML file. \n",
    "\n",
    "```bash\n",
    "kubectl apply -f fashion-mnist-serving-default.yaml\n",
    "```\n",
    "\n",
    "#### Create sample data\n",
    "\n",
    "create sample data ( assuming you have python3 installed on your local machine). \n",
    "\n",
    "```bash\n",
    "# install virtualenv\n",
    "pip3 install virtualenv\n",
    "# create a virtual environment named 'env'\n",
    "virtualenv env\n",
    "# activiate environment\n",
    "source env/bin/activate\n",
    "# install required packages\n",
    "pip3 install tensorflow==2.1.0 tensorflow-datasets==2.1.0\n",
    "# run script to generate sample data. This will create/overwrite 'fashion_mnist_input.json'\n",
    "python create_sample_test.py\n",
    "# deactivate environment\n",
    "deactivate\n",
    "```\n",
    "#### Test inferences\n",
    "\n",
    "```bash\n",
    "# model name\n",
    "MODEL_NAME=fashion-mnist\n",
    "# IP \n",
    "CLUSTER_IP=$(kubectl -n istio-system get service kfserving-ingressgateway -o jsonpath='{.status.loadBalancer.ingress[0].ip}')\n",
    "# host\n",
    "HOST=$(kubectl get inferenceservice -n kubeflow $MODEL_NAME -o jsonpath='{.status.url}' | cut -d \"/\" -f 3)\n",
    "# file path\n",
    "INPUT_PATH=@./fashion_mnist_input.json\n",
    "# make post request using curl\n",
    "curl -v -H \"Host: ${HOST}\" http://$CLUSTER_IP/v1/models/$MODEL_NAME:predict -d $INPUT_PATH\n",
    "```\n",
    "\n",
    "#### Debug Inferenceservice\n",
    "\n",
    "```bash\n",
    "kubectl get inferenceservice -n kubeflow\n",
    "kubectl get kservice -n kubeflow\n",
    "kubectl get pods -n kubeflow | grep fashion-mnist\n",
    "kubectl logs -f <PREDICTOR_POD_NAME> -n kubeflow storage-initializer\n",
    "kubectl logs -f <PREDICTOR_POD_NAME> -n kubeflow kfserving-container\n",
    "```\n",
    "#### Delete inferenceservice\n",
    "\n",
    "```bash\n",
    "kubectl delete inferenceservice -n kubeflow fashion-mnist\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pre and post processing  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### KFserving : Pre and Post-Processing\n",
    "\n",
    "#### Create a transformer image\n",
    "\n",
    "```bash\n",
    "PROJECT_ID=$(gcloud config get-value core/project)\n",
    "IMAGE_NAME=fashion-mnist-processing\n",
    "IMAGE_NAME=gcr.io/$PROJECT_ID/$IMAGE_NAME\n",
    "IMAGE_TAG=latest\n",
    "\n",
    "# build image\n",
    "docker build -t $IMAGE_NAME:$IMAGE_TAG .\n",
    "# run locally to test\n",
    "docker run -it --rm $IMAGE_NAME:$IMAGE_TAG\n",
    "# authorize docker\n",
    "gcloud auth configure-docker --quiet\n",
    "# push image\n",
    "docker push $IMAGE_NAME:$IMAGE_TAG\n",
    "```\n",
    "\n",
    "#### Create KFserving inferenceservice\n",
    "\n",
    "Change the model storage URI in the `fashion-mnist-serving-with-processing.yaml`. eg. `gs://<GCS_BUCKET_NAME>/export`\n",
    "Apply the YAML file. \n",
    "\n",
    "```bash\n",
    "kubectl apply -f fashion-mnist-serving-with-processing.yaml\n",
    "```\n",
    "#### Create sample data\n",
    "\n",
    "create sample data ( assuming you have python3 installed on your local machine). \n",
    "\n",
    "```bash\n",
    "# install virtualenv\n",
    "pip3 install virtualenv\n",
    "# create a virtual environment named 'env'\n",
    "virtualenv env\n",
    "# activiate environment\n",
    "source env/bin/activate\n",
    "# install required packages\n",
    "pip install tensorflow==2.1.0 tensorflow-datasets==2.1.0 pillow\n",
    "# run script to generate sample data. This will create/overwrite 'fashion_mnist_input.json'\n",
    "python create_sample_test_encoded.py\n",
    "# deactivate environment\n",
    "deactivate\n",
    "```\n",
    "\n",
    "#### Test inference\n",
    "\n",
    "Test on the sample json that contains `base64` encoded images. \n",
    "\n",
    "```bash\n",
    "# model name\n",
    "MODEL_NAME=fashion-mnist-processor\n",
    "# IP \n",
    "CLUSTER_IP=$(kubectl -n istio-system get service kfserving-ingressgateway -o jsonpath='{.status.loadBalancer.ingress[0].ip}')\n",
    "# host\n",
    "HOST=$(kubectl get inferenceservice -n kubeflow $MODEL_NAME -o jsonpath='{.status.url}' | cut -d \"/\" -f 3)\n",
    "# file path\n",
    "INPUT_PATH=@./fashion_mnist_input_b64_encoded.json\n",
    "# make post request using curl\n",
    "curl -v -H \"Host: ${HOST}\" http://$CLUSTER_IP/v1/models/$MODEL_NAME:predict -d $INPUT_PATH\n",
    "```\n",
    "\n",
    "### Test directly on image\n",
    "\n",
    "Try changing the images. \n",
    "\n",
    "```bash\n",
    "(echo -n '{\"instances\": [\"'; base64 fashion_mnist_1.jpg; echo '\"]}') | curl -v -H \"Content-Type: application/json\" -H \"Host: ${HOST}\" -d @-  http://$CLUSTER_IP/v1/models/$MODEL_NAME:predict\n",
    "```\n",
    "\n",
    "#### Debug Inferenceservice\n",
    "\n",
    "```bash\n",
    "kubectl get inferenceservice -n kubeflow\n",
    "kubectl get kservice -n kubeflow\n",
    "kubectl get pods -n kubeflow | grep fashion-mnist-processor\n",
    "kubectl logs -f <PREDICTOR_POD_NAME> -n kubeflow storage-initializer\n",
    "kubectl logs -f <PREDICTOR_POD_NAME> -n kubeflow kfserving-container\n",
    "kubectl logs -f <TRANSFORMER_POD_NAME> -n kubeflow user-container\n",
    "```\n",
    "#### Delete inferenceservice\n",
    "\n",
    "```bash\n",
    "kubectl delete inferenceservice -n kubeflow fashion-mnist-processor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
