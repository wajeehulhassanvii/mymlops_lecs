{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WORKFLOW steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Setup environment\n",
    "- Fairing (notebook kubernetes cluster, utilizes local computer as well, saving resource)\n",
    "- Modeling - Script on multi node/multi worker\n",
    "- Modeling with metadata tracking (Notebook - CPU training, export model to GCS)\n",
    "- Modeling NOTEBOOK - GPU\n",
    "- Hyperparameter - Script - Katib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KF - Notebook\n",
    "    - Notebook server\n",
    "    - can use pre-existing or custom docker image based on scenario\n",
    "    - KF nb also provieds authentication and access controls based on the requirement\n",
    "    - we can attach persistent volume for data or workspace\n",
    "    - configure resoures (CPU, RAM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### start kf environment\n",
    "- we can use pre-built docker image \n",
    "- open ingress and then go to KF dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Persistent Storage** will get destroyed if we uninstall KF, but will remain even if we delete notebook server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can mount one or more data volume to notebook server, can use diff sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install can install any package, we already have TF and NP in the pre-built package though."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUSTOM IMAGE TO GCR (Google Container Registry), then to KF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- build docker image\n",
    "- push image to GCR\n",
    "- Use custom image to setup notebook server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why custom image?\n",
    "- when prebuilt images aren't sufficient for use case\n",
    "- custom images for different teams or use cases eg, exploration, classical machine learning, deep learning (TF/Pytorch/etc)\n",
    "- we can have central team managing custom images for faster onboarding of data scientists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in our custom image, we are pip installing tensorflow, google-cloud-storage, kubeflow-metadata, pandas, end setting ENV NB_PREFIX /"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### to send image to google registry we need to have image in a certain format"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "PROJECT_ID=$(gcloud config get-value core/project)\n",
    "IMAGE_NAME=tensorflow-2.1.0-jupyter\n",
    "IMAGE_NAME=gcr.io/$PROJECT_ID/$IMAGE_NAME\n",
    "IMAGE_TAG=latest\n",
    "\n",
    "echo $IMAGE_NAME:$IMAGE_TAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### build docker image now"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "docker build -t $IMAGE_NAME:$IMAGE_TAG ."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "then run locally for teesting by\n",
    "docker run -it -p 8888:8888 -p 6006:6006 -v ${BASE_DIR}/mount_vol $IMAGE_NAME:$IMAGE_TAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### docker image building completed, now authorize docker as"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "docker run -it -p 8888:8888 -p 6006:6006 -v ${BASE_DIR}/mount_vol $IMAGE_NAME:$IMAGE_TAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### now sign in for google container registry "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "gcloud auth configure-docker --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### next push image"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "docker push $IMAGE_NAME:$IMAGE_TAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**after the image has been pushed. copy the link to access it which will be used for our new custom Notebook server**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEPS TO CONNECT TO KF NOTEBOOK SERVER\n",
    "- Go to Clusters tab in GKE\n",
    "- Select the cluster, copy the command and paste it in local terminal for accessing the cluster\n",
    "- then run the command \"kubectl get notebook mycustomnotebook -n (namespace of notebook server)\"\n",
    "- we can describe the notebook as **(kubectl describe notebook (notebook name) -n (namespace of notebook server)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TRADITIONAL WORKFLOW "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Structured code\n",
    "its best to structure the notebook code in different methods\n",
    "- prepare_data (load, scale, split), return train_ds, test_ds\n",
    "- build_model (Keras model, and model.compile), return model\n",
    "- get_callbacks, will have customLob class and on_epoch_end func, return callbacks\n",
    "- train the model now\n",
    "- evaluate the model as well\n",
    "- run tensorboard from terminal (connected KF terminal in local, **first connect to pod by port forwarding which has 6006 for tensorboard**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SAVE MODEL FROM GCS\n",
    "- we can save the model in kubeflow and in gcs_storage as well.\n",
    "- to store in gcs bucket, credentials will be the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KUBEFLOW FOR MULTI-USER (KUBEFLOW-METADATA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- track and manage metadata for ML workflow\n",
    "- backend db for string info\n",
    "- API to query and retrieve info, we can build custom app or UI using these apis OR\n",
    "- we can use artefact store dashbourd\n",
    "- Track metadata about\n",
    "    - model\n",
    "    - metric\n",
    "    - Dataset used to generate modeL"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from kubeflow.metadata import metadata\n",
    "import pandas\n",
    "from datetime import datetime\n",
    "from uuid import uiud\n",
    "\n",
    "METADATA_STORE_HOST = \"metadata-grpc-service.kubeflow\" # default DNS of kubeflow Metadata gRPC service\n",
    "METADATA_STORE_PORT = 8000"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "workspace = metadata.Workspace(\n",
    "    store=metadata.Store(grpc_host=METADATA_STORE_HOST, grpc_port=METADATA_STORE_PORT),\n",
    "    name=\"workspace_waj\",\n",
    "    description=\"workspace for first mnist on KF\",\n",
    "    labels={\"name\", \"user-1\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create runs from Kubeflow_metadata\n",
    "- Runs are logical grouping of multiple execution and we want to track different execution where each execution may involve diff experiment\n",
    "- for each execution we can store diff info"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model = exec.log_output(\n",
    "    metadata.Model(name, description, etc etc check from kubeflow docs)\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "metadata.Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can also build cusotm dashboard for team requirement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### learn more about metadata from kubeflow documentations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
